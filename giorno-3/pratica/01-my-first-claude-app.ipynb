{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giorno 3 - Pratica: My First Claude App\n",
    "\n",
    "## Obiettivi\n",
    "- Setup ambiente e libreria Anthropic\n",
    "- Prima chiamata API\n",
    "- Esperimenti con parametri\n",
    "- Costruire un chatbot CLI\n",
    "\n",
    "**Durata:** 3h 30min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parte 0: Setup Ambiente (30 min)\n",
    "\n",
    "### 0.1 Installazione Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installa le librerie necessarie\n",
    "!pip install anthropic python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Creazione Account API\n",
    "\n",
    "1. Vai su [console.anthropic.com](https://console.anthropic.com)\n",
    "2. Crea un account (o accedi)\n",
    "3. Vai su \"API Keys\"\n",
    "4. Clicca \"Create Key\"\n",
    "5. Copia la chiave (inizia con `sk-ant-...`)\n",
    "\n",
    "**IMPORTANTE:** Non condividere mai questa chiave!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Configurazione API Key\n",
    "\n",
    "**Metodo 1: Variabile d'ambiente (consigliato)**\n",
    "\n",
    "Nel terminale:\n",
    "```bash\n",
    "export ANTHROPIC_API_KEY=\"sk-ant-...\"\n",
    "```\n",
    "\n",
    "**Metodo 2: File .env (alternativa)**\n",
    "\n",
    "Crea un file `.env` nella stessa cartella:\n",
    "```\n",
    "ANTHROPIC_API_KEY=sk-ant-...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica la API key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carica .env se presente\n",
    "load_dotenv()\n",
    "\n",
    "# Verifica che la key esista\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "if api_key:\n",
    "    print(f\"API Key trovata: {api_key[:10]}...\")\n",
    "else:\n",
    "    print(\"ATTENZIONE: API Key non trovata!\")\n",
    "    print(\"Imposta ANTHROPIC_API_KEY come variabile d'ambiente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizializza il client Anthropic\n",
    "from anthropic import Anthropic\n",
    "\n",
    "client = Anthropic()  # Usa automaticamente ANTHROPIC_API_KEY\n",
    "print(\"Client Anthropic inizializzato con successo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parte 1: Prima Chiamata API (30 min)\n",
    "\n",
    "### 1.1 Hello Claude!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La nostra prima chiamata API!\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Ciao Claude! Presentati in italiano.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Esploriamo la Risposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esaminiamo l'oggetto response\n",
    "print(\"=== STRUTTURA RISPOSTA ===\")\n",
    "print(f\"ID: {response.id}\")\n",
    "print(f\"Modello: {response.model}\")\n",
    "print(f\"Ruolo: {response.role}\")\n",
    "print(f\"Stop reason: {response.stop_reason}\")\n",
    "print(f\"\\n=== TOKEN ===\")\n",
    "print(f\"Input tokens: {response.usage.input_tokens}\")\n",
    "print(f\"Output tokens: {response.usage.output_tokens}\")\n",
    "print(f\"Totale: {response.usage.input_tokens + response.usage.output_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Esercizio: La Tua Prima Chiamata\n",
    "\n",
    "Modifica il codice sotto per fare una domanda a tua scelta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrivi la tua domanda\n",
    "mia_domanda = \"[SCRIVI QUI LA TUA DOMANDA]\"\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": mia_domanda}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Domanda: {mia_domanda}\")\n",
    "print(f\"\\nRisposta: {response.content[0].text}\")\n",
    "print(f\"\\n[Token: {response.usage.input_tokens} + {response.usage.output_tokens}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parte 2: Esperimenti con Parametri (45 min)\n",
    "\n",
    "### 2.1 Confronto Modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stesso prompt su modelli diversi\n",
    "prompt = \"Spiega la fotosintesi in una frase.\"\n",
    "\n",
    "models = [\n",
    "    \"claude-3-haiku-20240307\",\n",
    "    \"claude-3-sonnet-20240229\",\n",
    "    # \"claude-3-opus-20240229\"  # Decommentare se vuoi testare (più costoso)\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    print(f\"\\n=== {model} ===\")\n",
    "    response = client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=256,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Osservazioni:**\n",
    "- Quale modello ha dato la risposta migliore?\n",
    "- Hai notato differenze di stile?\n",
    "\n",
    "_[Scrivi qui]_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Esperimenti con Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stesso prompt con temperature diverse\n",
    "prompt = \"Inventa un nome per una startup di AI.\"\n",
    "\n",
    "temperatures = [0.0, 0.5, 1.0, 1.5]\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(f\"\\n=== Temperature: {temp} ===\")\n",
    "    # Facciamo 3 tentativi per vedere la variabilità\n",
    "    for i in range(3):\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-haiku-20240307\",\n",
    "            max_tokens=50,\n",
    "            temperature=temp,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        print(f\"  {i+1}. {response.content[0].text.strip()[:50]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Osservazioni:**\n",
    "- Temperature 0.0: risposte ripetitive o diverse?\n",
    "- Temperature alta: più creatività?\n",
    "\n",
    "_[Scrivi qui]_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Effetto di max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vedere l'effetto del limite token\n",
    "prompt = \"Racconta la storia di Cappuccetto Rosso.\"\n",
    "\n",
    "for max_tok in [50, 150, 500]:\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=max_tok,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    print(f\"\\n=== max_tokens: {max_tok} (usati: {response.usage.output_tokens}) ===\")\n",
    "    print(f\"Stop reason: {response.stop_reason}\")\n",
    "    print(response.content[0].text[:200] + \"...\" if len(response.content[0].text) > 200 else response.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stesso prompt, system prompt diversi\n",
    "user_prompt = \"Cos'è Python?\"\n",
    "\n",
    "system_prompts = [\n",
    "    \"Rispondi come un professore universitario formale.\",\n",
    "    \"Rispondi come uno YouTuber entusiasta.\",\n",
    "    \"Rispondi in massimo 10 parole.\",\n",
    "    \"Rispondi usando solo emoji e una parola.\"\n",
    "]\n",
    "\n",
    "for system in system_prompts:\n",
    "    print(f\"\\n=== System: {system[:40]}... ===\")\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=256,\n",
    "        system=system,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    )\n",
    "    print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parte 3: Gestione Conversazioni Multi-turn (45 min)\n",
    "\n",
    "### 3.1 Problema: Claude Non Ricorda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chiamata 1\n",
    "response1 = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=256,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Mi chiamo Marco. Ricordalo!\"}]\n",
    ")\n",
    "print(\"Risposta 1:\", response1.content[0].text)\n",
    "\n",
    "# Chiamata 2 (separata)\n",
    "response2 = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=256,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Come mi chiamo?\"}]\n",
    ")\n",
    "print(\"\\nRisposta 2:\", response2.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Soluzione: Passare la Cronologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chiamata 1\n",
    "messages = [{\"role\": \"user\", \"content\": \"Mi chiamo Marco. Ricordalo!\"}]\n",
    "\n",
    "response1 = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=256,\n",
    "    messages=messages\n",
    ")\n",
    "print(\"Risposta 1:\", response1.content[0].text)\n",
    "\n",
    "# Aggiungi la risposta alla cronologia\n",
    "messages.append({\"role\": \"assistant\", \"content\": response1.content[0].text})\n",
    "\n",
    "# Chiamata 2 (con cronologia)\n",
    "messages.append({\"role\": \"user\", \"content\": \"Come mi chiamo?\"})\n",
    "\n",
    "response2 = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=256,\n",
    "    messages=messages\n",
    ")\n",
    "print(\"\\nRisposta 2:\", response2.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Classe ChatSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatSession:\n",
    "    \"\"\"\n",
    "    Gestisce una sessione di chat con Claude.\n",
    "    Mantiene la cronologia dei messaggi.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, system_prompt=\"Sei un assistente utile.\"):\n",
    "        self.client = Anthropic()\n",
    "        self.system = system_prompt\n",
    "        self.messages = []\n",
    "\n",
    "    def send(self, user_message):\n",
    "        \"\"\"Invia un messaggio e ottieni la risposta.\"\"\"\n",
    "        # Aggiungi messaggio utente\n",
    "        self.messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_message\n",
    "        })\n",
    "\n",
    "        # Chiama API\n",
    "        response = self.client.messages.create(\n",
    "            model=\"claude-3-haiku-20240307\",\n",
    "            max_tokens=1024,\n",
    "            system=self.system,\n",
    "            messages=self.messages\n",
    "        )\n",
    "\n",
    "        # Estrai risposta\n",
    "        assistant_message = response.content[0].text\n",
    "\n",
    "        # Salva nella cronologia\n",
    "        self.messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": assistant_message\n",
    "        })\n",
    "\n",
    "        return assistant_message, response.usage\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"Pulisce la cronologia.\"\"\"\n",
    "        self.messages = []\n",
    "\n",
    "    def get_history(self):\n",
    "        \"\"\"Restituisce la cronologia.\"\"\"\n",
    "        return self.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test della classe\n",
    "chat = ChatSession(\"Sei un tutor di Python paziente e incoraggiante.\")\n",
    "\n",
    "risposta, usage = chat.send(\"Ciao! Voglio imparare Python.\")\n",
    "print(f\"Claude: {risposta}\\n\")\n",
    "\n",
    "risposta, usage = chat.send(\"Da dove comincio?\")\n",
    "print(f\"Claude: {risposta}\\n\")\n",
    "\n",
    "risposta, usage = chat.send(\"Cos'è una variabile?\")\n",
    "print(f\"Claude: {risposta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vediamo la cronologia\n",
    "print(\"=== CRONOLOGIA ===\")\n",
    "for msg in chat.get_history():\n",
    "    print(f\"\\n[{msg['role'].upper()}]\")\n",
    "    print(msg['content'][:100] + \"...\" if len(msg['content']) > 100 else msg['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parte 4: Chatbot CLI Completo (45 min)\n",
    "\n",
    "### 4.1 Chatbot Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_chatbot():\n",
    "    \"\"\"Chatbot CLI semplice.\"\"\"\n",
    "    print(\"=\"*50)\n",
    "    print(\"CHATBOT CLAUDE\")\n",
    "    print(\"Scrivi 'quit' per uscire\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    chat = ChatSession(\"Sei un assistente amichevole che risponde in italiano.\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\nTu: \").strip()\n",
    "\n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"\\nArrivederci!\")\n",
    "            break\n",
    "\n",
    "        if not user_input:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            risposta, usage = chat.send(user_input)\n",
    "            print(f\"\\nClaude: {risposta}\")\n",
    "            print(f\"\\n[Token: {usage.input_tokens} + {usage.output_tokens}]\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nErrore: {e}\")\n",
    "\n",
    "# Esegui il chatbot\n",
    "# simple_chatbot()  # Decommenta per eseguire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Chatbot con Funzionalità Avanzate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedChatbot:\n",
    "    \"\"\"\n",
    "    Chatbot avanzato con comandi speciali.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = Anthropic()\n",
    "        self.messages = []\n",
    "        self.system = \"Sei un assistente utile che risponde in italiano.\"\n",
    "        self.model = \"claude-3-haiku-20240307\"\n",
    "        self.total_tokens = 0\n",
    "\n",
    "    def process_command(self, command):\n",
    "        \"\"\"Gestisce i comandi speciali.\"\"\"\n",
    "        cmd = command.lower().strip()\n",
    "\n",
    "        if cmd == '/help':\n",
    "            return \"\"\"\n",
    "Comandi disponibili:\n",
    "  /help     - Mostra questo messaggio\n",
    "  /clear    - Pulisce la cronologia\n",
    "  /history  - Mostra la cronologia\n",
    "  /tokens   - Mostra token totali usati\n",
    "  /system   - Cambia system prompt\n",
    "  /quit     - Esci dal chatbot\n",
    "\"\"\"\n",
    "\n",
    "        elif cmd == '/clear':\n",
    "            self.messages = []\n",
    "            return \"Cronologia cancellata.\"\n",
    "\n",
    "        elif cmd == '/history':\n",
    "            if not self.messages:\n",
    "                return \"Nessun messaggio nella cronologia.\"\n",
    "            result = \"\\n=== CRONOLOGIA ===\\n\"\n",
    "            for msg in self.messages:\n",
    "                role = \"Tu\" if msg['role'] == 'user' else \"Claude\"\n",
    "                text = msg['content'][:50] + \"...\" if len(msg['content']) > 50 else msg['content']\n",
    "                result += f\"{role}: {text}\\n\"\n",
    "            return result\n",
    "\n",
    "        elif cmd == '/tokens':\n",
    "            return f\"Token totali usati: {self.total_tokens}\"\n",
    "\n",
    "        elif cmd.startswith('/system '):\n",
    "            self.system = cmd[8:]\n",
    "            return f\"System prompt aggiornato: {self.system}\"\n",
    "\n",
    "        return None  # Non è un comando\n",
    "\n",
    "    def chat(self, user_message):\n",
    "        \"\"\"Invia messaggio e ricevi risposta.\"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "        response = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=1024,\n",
    "            system=self.system,\n",
    "            messages=self.messages\n",
    "        )\n",
    "\n",
    "        assistant_message = response.content[0].text\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "\n",
    "        self.total_tokens += response.usage.input_tokens + response.usage.output_tokens\n",
    "\n",
    "        return assistant_message\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Esegue il chatbot.\"\"\"\n",
    "        print(\"=\"*50)\n",
    "        print(\"CHATBOT AVANZATO\")\n",
    "        print(\"Scrivi /help per i comandi\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        while True:\n",
    "            user_input = input(\"\\nTu: \").strip()\n",
    "\n",
    "            if not user_input:\n",
    "                continue\n",
    "\n",
    "            # Controlla comandi\n",
    "            if user_input.startswith('/'):\n",
    "                if user_input.lower() == '/quit':\n",
    "                    print(f\"\\nArrivederci! Token totali: {self.total_tokens}\")\n",
    "                    break\n",
    "                result = self.process_command(user_input)\n",
    "                if result:\n",
    "                    print(result)\n",
    "                    continue\n",
    "\n",
    "            # Chat normale\n",
    "            try:\n",
    "                risposta = self.chat(user_input)\n",
    "                print(f\"\\nClaude: {risposta}\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\nErrore: {e}\")\n",
    "                self.messages.pop()  # Rimuovi messaggio fallito\n",
    "\n",
    "# Esegui\n",
    "# bot = AdvancedChatbot()\n",
    "# bot.run()  # Decommenta per eseguire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parte 5: Salvataggio e Caricamento Conversazioni (30 min)\n",
    "\n",
    "### 5.1 Salvare su File JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "class PersistentChatbot:\n",
    "    \"\"\"\n",
    "    Chatbot che salva le conversazioni su file.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, save_file=\"chat_history.json\"):\n",
    "        self.client = Anthropic()\n",
    "        self.save_file = save_file\n",
    "        self.messages = []\n",
    "        self.system = \"Sei un assistente utile.\"\n",
    "        self.load_history()\n",
    "\n",
    "    def save_history(self):\n",
    "        \"\"\"Salva la cronologia su file.\"\"\"\n",
    "        data = {\n",
    "            \"system\": self.system,\n",
    "            \"messages\": self.messages,\n",
    "            \"last_updated\": datetime.now().isoformat()\n",
    "        }\n",
    "        with open(self.save_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"Cronologia salvata in {self.save_file}\")\n",
    "\n",
    "    def load_history(self):\n",
    "        \"\"\"Carica la cronologia da file.\"\"\"\n",
    "        try:\n",
    "            with open(self.save_file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            self.system = data.get(\"system\", self.system)\n",
    "            self.messages = data.get(\"messages\", [])\n",
    "            print(f\"Caricati {len(self.messages)} messaggi da {self.save_file}\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"Nessuna cronologia precedente trovata.\")\n",
    "\n",
    "    def chat(self, user_message):\n",
    "        \"\"\"Invia messaggio e salva.\"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "        response = self.client.messages.create(\n",
    "            model=\"claude-3-haiku-20240307\",\n",
    "            max_tokens=1024,\n",
    "            system=self.system,\n",
    "            messages=self.messages\n",
    "        )\n",
    "\n",
    "        assistant_message = response.content[0].text\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "\n",
    "        self.save_history()  # Salva dopo ogni messaggio\n",
    "\n",
    "        return assistant_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test del chatbot persistente\n",
    "pbot = PersistentChatbot(\"test_chat.json\")\n",
    "\n",
    "print(pbot.chat(\"Ciao! Oggi è una bella giornata.\"))\n",
    "print(\"\\n\" + pbot.chat(\"Di cosa stavamo parlando?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica il file salvato\n",
    "with open(\"test_chat.json\", 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Esercizi Finali\n",
    "\n",
    "### Esercizio 1: Chatbot Personalizzato\n",
    "\n",
    "Crea un chatbot con un system prompt personalizzato per un caso d'uso specifico (es: tutor di matematica, consulente fitness, assistente cucina)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il tuo chatbot personalizzato\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "[SCRIVI IL TUO SYSTEM PROMPT]\n",
    "\"\"\"\n",
    "\n",
    "chat = ChatSession(system_prompt)\n",
    "\n",
    "# Test con alcune domande\n",
    "print(chat.send(\"[LA TUA PRIMA DOMANDA]\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio 2: Batch Processing\n",
    "\n",
    "Crea una funzione che prende una lista di domande e restituisce tutte le risposte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_questions(questions, system=\"Rispondi in modo conciso.\"):\n",
    "    \"\"\"\n",
    "    Elabora una lista di domande in batch.\n",
    "\n",
    "    Args:\n",
    "        questions: lista di stringhe\n",
    "        system: system prompt da usare\n",
    "\n",
    "    Returns:\n",
    "        lista di tuple (domanda, risposta, token_usati)\n",
    "    \"\"\"\n",
    "    # [IMPLEMENTA LA FUNZIONE]\n",
    "    pass\n",
    "\n",
    "\n",
    "# Test\n",
    "domande = [\n",
    "    \"Qual è la capitale della Francia?\",\n",
    "    \"Quanto fa 15 * 7?\",\n",
    "    \"Chi ha scritto la Divina Commedia?\"\n",
    "]\n",
    "\n",
    "# risultati = batch_questions(domande)\n",
    "# for q, a, t in risultati:\n",
    "#     print(f\"D: {q}\")\n",
    "#     print(f\"R: {a}\")\n",
    "#     print(f\"Token: {t}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusione\n",
    "\n",
    "### Cosa abbiamo imparato:\n",
    "\n",
    "1. **Setup API** - Configurazione client e API key\n",
    "2. **Chiamate base** - Struttura richiesta/risposta\n",
    "3. **Parametri** - model, max_tokens, temperature, system\n",
    "4. **Multi-turn** - Gestire conversazioni con cronologia\n",
    "5. **Persistenza** - Salvare e caricare conversazioni\n",
    "\n",
    "### Prossimi passi:\n",
    "Domani esploreremo **Claude Code** per lo sviluppo assistito da AI!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
